#!/usr/bin/env python3
"""
GPUä¼˜åŒ–è®­ç»ƒè„šæœ¬
é’ˆå¯¹CUDAè®¾å¤‡ä¼˜åŒ–çš„é«˜é€Ÿè®­ç»ƒé…ç½®
"""

import torch
import time
import os
from hppoTrainer import Trainer
from config import TrainingConfig


def check_gpu_status():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    print("=" * 50)
    print("GPUçŠ¶æ€æ£€æŸ¥")
    print("=" * 50)

    if torch.cuda.is_available():
        print(f"âœ… CUDAå¯ç”¨")
        print(f"GPUæ•°é‡: {torch.cuda.device_count()}")
        print(f"å½“å‰GPU: {torch.cuda.current_device()}")
        print(f"GPUåç§°: {torch.cuda.get_device_name()}")
        print(f"GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")

        # æ£€æŸ¥GPUå†…å­˜ä½¿ç”¨
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print(f"å¯ç”¨å†…å­˜: {torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()} bytes")

        return True
    else:
        print("âŒ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆä¼šå¾ˆæ…¢ï¼‰")
        return False


def optimize_pytorch_settings():
    """ä¼˜åŒ–PyTorchè®¾ç½®ä»¥æé«˜GPUæ€§èƒ½"""
    print("\n" + "=" * 50)
    print("PyTorchæ€§èƒ½ä¼˜åŒ–è®¾ç½®")
    print("=" * 50)

    # å¯ç”¨cuDNNçš„è‡ªåŠ¨ä¼˜åŒ–
    if torch.cuda.is_available():
        torch.backends.cudnn.benchmark = True
        torch.backends.cudnn.deterministic = False
        print("âœ… å¯ç”¨cuDNNåŸºå‡†æ¨¡å¼")

        # è®¾ç½®GPUå†…å­˜åˆ†é…ç­–ç•¥
        os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
        print("âœ… ä¼˜åŒ–CUDAå†…å­˜åˆ†é…")

    # è®¾ç½®çº¿ç¨‹æ•°
    torch.set_num_threads(4)  # ä¸è¦è®¾ç½®å¤ªé«˜ï¼Œé¿å…ä¸GPUç«äº‰
    print(f"âœ… è®¾ç½®CPUçº¿ç¨‹æ•°: {torch.get_num_threads()}")

    # ç¦ç”¨æ¢¯åº¦æ£€æŸ¥ä»¥æé«˜é€Ÿåº¦ï¼ˆåœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼‰
    torch.autograd.set_detect_anomaly(False)
    print("âœ… ç¦ç”¨æ¢¯åº¦å¼‚å¸¸æ£€æµ‹ï¼ˆæé«˜é€Ÿåº¦ï¼‰")


def main():
    """ä¸»è®­ç»ƒå‡½æ•°"""
    print("ğŸš€ å¯åŠ¨GPUä¼˜åŒ–è®­ç»ƒ")
    print("=" * 50)

    # æ£€æŸ¥GPUçŠ¶æ€
    gpu_available = check_gpu_status()

    # ä¼˜åŒ–PyTorchè®¾ç½®
    optimize_pytorch_settings()

    # æ£€æŸ¥å¥–åŠ±æ³¢åŠ¨é—®é¢˜ï¼Œæä¾›é…ç½®å»ºè®®
    print(f"\nğŸ“‹ é…ç½®æ¨¡å¼é€‰æ‹©:")
    print(f"  ğŸš„ gpu_optimized: æœ€å¤§åŒ–è®­ç»ƒé€Ÿåº¦ (å¯èƒ½æœ‰å¥–åŠ±æ³¢åŠ¨)")
    print(f"  ğŸ¯ stable_gpu: å¹³è¡¡é€Ÿåº¦å’Œç¨³å®šæ€§ (æ¨è)")
    print(f"  ğŸ”§ stable: æœ€å¤§åŒ–ç¨³å®šæ€§ (è¾ƒæ…¢)")

    # é»˜è®¤ä½¿ç”¨ç¨³å®šGPUé…ç½®ï¼Œé™¤éç”¨æˆ·æœ‰ç‰¹æ®Šéœ€æ±‚
    config_mode = 'stable_gpu'  # ä»gpu_optimizedæ”¹ä¸ºstable_gpu

    # åˆ›å»ºé…ç½®
    config = TrainingConfig(config_mode)

    # å¦‚æœGPUä¸å¯ç”¨ï¼Œé™çº§åˆ°CPUä¼˜åŒ–é…ç½®
    if not gpu_available:
        print("\nâš ï¸ GPUä¸å¯ç”¨ï¼Œåˆ‡æ¢åˆ°CPUä¼˜åŒ–æ¨¡å¼")
        config.batch_size = min(config.batch_size, 64)  # é™åˆ¶æ‰¹å¤„ç†å¤§å°
        config.buffer_size = min(config.buffer_size, 4000)  # é™åˆ¶ç¼“å†²åŒº
        config.device = torch.device('cpu')
        # CPUæ¨¡å¼ä¸‹è¿›ä¸€æ­¥é™ä½å­¦ä¹ ç‡æé«˜ç¨³å®šæ€§
        config.lr_actor *= 0.7
        config.lr_critic *= 0.7

    print(f"\nğŸ“Š è®­ç»ƒé…ç½®æ¦‚è§ˆ:")
    print(f"é…ç½®æ¨¡å¼: {config_mode.upper()}")
    print(f"è®¾å¤‡: {config.device}")
    print(f"æ‰¹å¤„ç†å¤§å°: {config.batch_size}")
    print(f"ç¼“å†²åŒºå¤§å°: {config.buffer_size}")
    print(f"æ›´æ–°é¢‘ç‡: {config.agent_update_freq}")
    print(f"ç½‘ç»œç»“æ„: {config.mid_dim}")
    print(f"å­¦ä¹ ç‡: Actor={config.lr_actor}, Critic={config.lr_critic}")
    print(f"æœ€å¤§è½®æ¬¡: {config.max_episodes}")

    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = Trainer(config)

    print(f"\nğŸ¯ å¼€å§‹ç¨³å®šæ€§ä¼˜åŒ–è®­ç»ƒ...")
    print(f"ğŸ’¡ æç¤º: å¦‚æœä»æœ‰å¥–åŠ±æ³¢åŠ¨ï¼Œè®­ç»ƒå™¨ä¼šè‡ªåŠ¨æä¾›è°ƒä¼˜å»ºè®®")
    start_time = time.time()

    # åˆå§‹åŒ–è®­ç»ƒæ—¶é—´å˜é‡
    training_time = 0.0

    try:
        # æ‰§è¡Œè®­ç»ƒ
        trainer.train(worker_idx=1)

        # è®¡ç®—è®­ç»ƒæ—¶é—´
        training_time = time.time() - start_time

        # ä¿å­˜ç»“æœå¹¶ç”Ÿæˆæœ€ç»ˆåˆ†æ
        print(f"\nğŸ¨ æ­£åœ¨ç”Ÿæˆè®­ç»ƒç»“æœåˆ†æ...")

        # ä¿å­˜è®­ç»ƒæ•°æ®
        trainer._save_final_results()

        # ç”Ÿæˆæœ€ç»ˆçš„å®Œæ•´åˆ†æå›¾è¡¨
        if trainer.total_rewards:
            print("ğŸ“Š ç”Ÿæˆè®­ç»ƒåˆ†æå›¾è¡¨...")
            trainer._create_comprehensive_plots()

            print("ğŸ“ˆ ç”Ÿæˆå¥–åŠ±åˆ†æå›¾è¡¨...")
            trainer._create_reward_analysis_plot(len(trainer.total_rewards))

            print("ğŸ“Š å®Œæ•´è®­ç»ƒåˆ†æå›¾è¡¨å·²ç”Ÿæˆ")

        # ç”Ÿæˆæœ€ç»ˆç¯å¢ƒçŠ¶æ€å¯è§†åŒ–
        print("ğŸ—ºï¸ ç”Ÿæˆæœ€ç»ˆç¯å¢ƒçŠ¶æ€å›¾...")
        final_env_path = trainer.save_path + 'final_environment_state.png'
        trainer.env.visualize_environment(final_env_path)
        print(f"ğŸ–¼ï¸ æœ€ç»ˆç¯å¢ƒçŠ¶æ€å·²ä¿å­˜: {final_env_path}")

        # ç”Ÿæˆæœ€ç»ˆæ€§èƒ½æ€»ç»“
        print("ğŸ“‹ ç”Ÿæˆæ€§èƒ½æ€»ç»“æŠ¥å‘Š...")
        performance_metrics = trainer.env.get_performance_metrics()
        reward_stats = trainer.env.get_reward_statistics()

        summary_text = f"""
è®­ç»ƒæ€»ç»“æŠ¥å‘Š
{'=' * 50}
è®­ç»ƒé…ç½®: {config_mode.upper()} æ¨¡å¼
è®¾å¤‡: {config.device}
è®­ç»ƒè½®æ¬¡: {len(trainer.total_rewards)}
è®­ç»ƒç”¨æ—¶: {training_time / 60:.1f}åˆ†é’Ÿ

å¥–åŠ±è¡¨ç°:
- å¹³å‡å¥–åŠ±: {sum(trainer.total_rewards) / len(trainer.total_rewards):.3f}
- æœ€é«˜å¥–åŠ±: {max(trainer.total_rewards):.3f}
- æœ€ä½å¥–åŠ±: {min(trainer.total_rewards):.3f}
- æœ€ç»ˆ50è½®å¹³å‡: {sum(trainer.total_rewards[-50:]) / min(50, len(trainer.total_rewards)):.3f}

ç¯å¢ƒè¡¨ç°:
- æ•°æ®æ”¶é›†å®Œæˆç‡: {performance_metrics['data_completion_rate']:.1%}
- å¹³å‡å®šä½ä¸ç¡®å®šæ€§: {performance_metrics['average_uncertainty']:.1f}m
- é€šä¿¡æ¬¡æ•°: {performance_metrics['communication_count']}
- å®šä½æ¬¡æ•°: {performance_metrics['localization_count']}

æŠ€èƒ½å‘å±•:
- é€šä¿¡æŠ€èƒ½: {reward_stats.get('communication_skill', 0):.3f}
- å®šä½æŠ€èƒ½: {reward_stats.get('localization_skill', 0):.3f}
- é€šä¿¡æˆåŠŸç‡: {reward_stats.get('communication_success_rate', 0):.1%}
- å®šä½æˆåŠŸç‡: {reward_stats.get('localization_success_rate', 0):.1%}

è®­ç»ƒæ•ˆç‡:
- å¹³å‡æ¯è½®ç”¨æ—¶: {training_time / len(trainer.total_rewards):.2f}ç§’
- è®­ç»ƒé€Ÿåº¦: {len(trainer.total_rewards) / (training_time / 60):.1f} episodes/åˆ†é’Ÿ
"""

        # ä¿å­˜æ€»ç»“æŠ¥å‘Š
        with open(trainer.save_path + 'training_summary.txt', 'w', encoding='utf-8') as f:
            f.write(summary_text)

        print("ğŸ“„ è®­ç»ƒæ€»ç»“æŠ¥å‘Šå·²ä¿å­˜")
        print("ğŸ’¾ æ‰€æœ‰ç»“æœå·²ä¿å­˜å®Œæˆ")

        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"æ€»ç”¨æ—¶: {training_time / 60:.1f}åˆ†é’Ÿ")
        print(f"å¹³å‡æ¯è½®ç”¨æ—¶: {training_time / config.max_episodes:.2f}ç§’")

        # æ˜¾ç¤ºæœ€ç»ˆæ€§èƒ½æŒ‡æ ‡
        if trainer.total_rewards:
            final_avg_reward = sum(trainer.total_rewards[-50:]) / min(50, len(trainer.total_rewards))
            print(f"æœ€ç»ˆå¹³å‡å¥–åŠ±(æœ€å50è½®): {final_avg_reward:.3f}")

            # è®¡ç®—è®­ç»ƒé€Ÿåº¦æå‡
            episodes_per_minute = len(trainer.total_rewards) / (training_time / 60)
            print(f"è®­ç»ƒé€Ÿåº¦: {episodes_per_minute:.1f} episodes/åˆ†é’Ÿ")

    except KeyboardInterrupt:
        training_time = time.time() - start_time
        print(f"\nâ¹ï¸ è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        print(f"å·²è®­ç»ƒæ—¶é—´: {training_time / 60:.1f}åˆ†é’Ÿ")

    except Exception as e:
        training_time = time.time() - start_time
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
            print("ğŸ§¹ GPUå†…å­˜å·²æ¸…ç†")


if __name__ == "__main__":
    main()